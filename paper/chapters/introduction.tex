\section{Introduction}
%% Version 1 (Score 100)
As we witness a significant growth of video content consumption on the internet over the past two decades, the ability to assess the QoE of the end user is becoming critical.


% Video content, rightfully, has become one of the predominant resources on the Internet over the past few years.
% As the quality of the streamed video is highly dependant on the channel it is being transmitted on, the Internet Service Providers (ISPs) are in an unique position to influence it directly, e.g., by increasing the the Band Width (BW), cache video content on servers on the Content Delivery Network (CDN), etc.

% Traffic manipulation by the ISP is usually done with tools that analyze the quality of the transferred data through a Deep Packet Inspection (DPI) tools, e.g., Wireshark, and apply traffic-enhancing algorithms to enhance the QoE of the end users. 
%% Version 1 (Score 100)
As the data communication channel plays an integral role in the final video quality, Internet Service Providers (ISPs) are placed in a unique position of being able to influence it directly, e.g., by temporarily increasing the bandwidth of a "content-hungry" network segments, or by caching the data on a Content Delivery Networks (CDNs), etc.

As most of the video content is streamed over an end-to-end encrypted channels, this procedure becoming increasingly more challenging for the ISP. While the Video Content Providers (VCP) may derive the quality of the streamed video fairly easily, e.g., by directly comparing the original image to the image which is presented to the end user, this procedure is not as straight forward to ISPs, as all they have access to is the metrics of the channel, which thought has a some indirect connection to the data streamed over it, but it is not clear how the observed metrics such as BW, latency and packet size can be related to the QoE of the end user, or even the image quality of the video.

This situation is further complected as users usually have more than a one application that requires data being transmitted over the internet. If we will add to this, the fact that in most cases data channels governed by the ISPs carry traffic which corresponds to multiple users, this problem complicates even folds more.

After the pandemic of 2019, VC application use surged \cite{chang2021can} \cite{feldmann2020lockdown}, and due to the wide adaption by many schools and organizations worldwide \cite{choi2022zoom} \cite{espin2021impact} \cite{nistico2020comparative}, QoE assessment in this domain remains a "hot" topic today.
% it's becoming more than ever relevant to provide a reliable QoE assessment tool also for this domain.
% and specifically for the Zoom VC application, as it was widely adapted by many schools and organizations worldwide \cite{choi2022zoom} \cite{espin2021impact} \cite{nistico2020comparative}.
% streams of many users is steamed over the same channel, 


% and along with this surge in demand, increases the need for Internet Service Providers (ISPs) to be able to analyze this traffic, which may be affected by a variety of factors (e.g., bandwidth, latency, packet size, etc.) 

% A large variety of traffic-enhancing algorithms and services are then applied to guarantee a good Quality of Experience (QoE). 

% Just to name a few of the services referred to above, some algorithms are designed to prioritize Voice over IP (VoIP), or services that cache the content on servers that are located closer to the end user, and by doing this, they reduce the delays in data traffic.

% Techniques for traffic manipulation, which use Deep Packet Inspection (DPI) tools, e.g., Wireshark, rely heavily on the ability of ISPs being able to analyze the data transmitted over the network. This process has become quite challenging in light of the increasing popularity of traffic encryption techniques employed in the network today, which prevents ISPs from their ability to guarantee to the end user an optimal QoE.

Though the term "good QoE" may be perceived by each individual on an intuitive level, as it is plausible to suppose that each person, if asked to rate a video, would be able to do it, it is hard to come up with a clear and objective definition to what criteria made the same person decide on the QoE of some particular video or image, as this decision usually hinges on the subjective judgment of the person asked. 

Nevertheless, we still may try to come up with a set of features that we call Key Performance Indicators (KPIs), that may exert influence when one evaluates a video. The most intuitive KPIs to recon on, are the technical ones (e.g., initial startup delay, number and duration of stalling events, and KPIs related to the image quality, viz. bit rate, and resolution.) Unfortunately, there are also quite a few features that have a less straightforward definition. Just to name a few of these are the context of the judgment (i.e., we require a higher quality presented on a higher quality monitor, or we would be less judgmental of an image of a lesser quality that is streamed over a mobile device, etc.), viewers attention to details, or even its emotional state, all may affect its final decision. 

Criteria that try to evaluate the QoE of some videos generally may be categorized into two classes, viz. Subjective and Objective. The main difference between the two classes may be summed up as the amount of human participation in the process of scoring. While criteria that correspond to the former category require full human involvement to acquire the rating, criteria that fall into the latter category can do without it.
 
One of the most widely used subjective criteria of QoE is the Mean Opinion Score (MOS), which was presented by ITU-T Focus Group on IPTV \cite{recommendation20081080}, and represents the overall acceptability of an application (or a service), perceived by the end user. It is calculated by averaging the scores assigned by participants (usually on a scale of five points) to video samples, which are designed to simulate a certain quality.

Objective criteria for QoE evaluation may be further divided into three subcategories, viz. full reference, reduced reference, and no reference, where the main difference between the three categories is the use of the original image in the evaluation process. While criteria that may be assigned to the first category use the original image as a reference to evaluate the corrupted image, criteria in the second category try to mitigate this dependence by using only the most important and easily acquired subset of features that may be used to predict the QoE. Criteria that fall into the last category go even further, i.e., they are completely independent of the original image.
% Video content, rightfully, has become one of the predominant resources in the internet over the past few years, and along with this surge in demand, increases the need of the Internet Service Providers (ISPs) to be able to analyze this traffic, which may be effected by a variety of factors (e.g., bandwidth, latency, packet size etc.) A large variety of traffic enhancing algorithms, and services are then applied to guarantee a good Quality of Experience (QoE). Just to name a few of the services referred above, there are algorithms which are designed to prioritize Voice over IP (VoIP), or services which cache the content on servers which are located closer to the end user, and by doing this, they reduce the delays in data traffic etc.
% Techniques for traffic manipulation, which use the Deep Packet Inspection (DPI) tools, e.g., wireshark, rely heavily on the ability of the ISPs being able to analyze the data transmitted in the network. This process has become quite challenging in the light of the increasing popularity of traffic encryption techniques employed in the network today, which prevents the ISPs of their ability to guarantee to the end user an optimal QoE.
% Though the term "good QoE" may be perceived by each individual on an intuitive level (as we all know what we expect from a good quality video), it is hard to come up with a clear and objective definition to what exactly it means, due to its heavy dependence on a large variety of factors, which not always objective. The most obvious, and also the easiest to recon on, are the technical ones, e.g, resolution, bit rate, delay between frames or the corruption of the image. Unfortunately, there are also quite a few features which have a less straight forward definition. Just to name a few, the context of the judgment (i.e., we require a higher quality presented on a higher quality monitor, or we would be less judgmental of an image of a lesser quality which is streamed over a mobile device etc.), viewers attention to details, or even its emotional state may affect its final decision. 
% One criterion which try to measure the QoE and assign a numeric value which represents it is the Mean Opinion Score (MOS), which was presented by ITU-T Focus Group on IPTV \cite{recommendation20081080}, and represents the overall acceptability of an application (or a service), perceived by the end user. It is calculated via averaging the scores assigned by participants (usually on a scale of five points) to video samples, which are designed to simulate a certain quality.



% Video is becoming the predominant Internet content. In the past, Internet Service Providers (ISPs) could monitor video quality in transit and apply various added value services to improve end-users' experience. For example, they prioritized multi-media content such as VoIP due to its sensitivity to real-time communication. Another example is edge caching, which brings the content closer to the subscriber in terms of network proximity, thus reducing network delays and bottlenecks. These operations were possible with Deep Packet Inspection (DPI) tools. However, today, most Internet content, including streaming video, is encrypted; therefore, ISPs had lost their ability to inspect the content, extract insights related to users experience and subsequently improve it.
% Video quality is impacted by multiple factors, including available network bandwidth and latency, devices and applications. According to the ITU-T Focus Group on IPTV ‎\cite{recommendation20081080}, QoE refers to the overall acceptability of an application or service, as perceived subjectively by the end-user. Assessment of video quality is subjective and depends on the viewer. Mean Opinion Score (MOS) is one of the well-known QoE metrics. It is based on observation and subjective classification by individual human viewers.
% Assessing the quality of encrypted video content is a challenge that has been researched in recent years. The primary focus had been Video on Demand (VOD) services such as YouTube, Netflix, Hulu, Amazon video, and the like ‎\cite{loh2020uplink}‎\cite{wassermann2019let}. These streaming video services use TCP, UDP, and in recent years QUIC transport protocols ‎‎\cite{langley2017quic}. 
% The Covid-19 pandemic has caused a significant rise in remote collaboration and the use of video conferencing as the primary mean of communication for business, education, and leisure purposes. The dominant video conferencing applications are Zoom, Microsoft Teams, and Google GoToMeeting; amongst them, Zoom conferencing is the most dominant application of choice ‎‎\cite{resources_owllabs}. 
% Several calculated QoE metrics can be extracted from video conferencing sessions to provide a meaningful representation of the Human Visual System (HVS). One of them is the VMAF ‎‎\cite{vmaf2018} (Video Multimethod Assessment Fusion) framework. VMAF is a full reference video quality estimation metric proposed by Netflix. It is considered a good QoE estimation compared to Mean Opinion Score (MOS) ‎\cite{li2018vmaf}.
% Quantization is used in lossy video compression algorithms. In compressed video streams, the Discrete Cosine Transform (DCT) block residuals are quantized such that higher spatial frequencies are zeroed up. The quantization parameter (Qp) of compressed video may be a good indication of video quality, assuming that we can estimate its value on a per frame basis from the encrypted network stream. To the best of our knowledge, this is the first research work to extract QoE of encrypted video conferencing traffic and Zoom in particular. 
% The main contribution of this paper is the inferencing of NIQE, fps, and spatial resolution QoE metrics of encrypted Zoom conferencing traffic. As a byproduct of this research work, we have also: 1) Explained observation of the unique Zoom network behavior patterns; 2) Extract low-level features from Zoom network encrypted traffic protocols to estimate the QoE according to a set of pre-defined labels. 3) Study the variation of Qp during a Zoom conference call.
